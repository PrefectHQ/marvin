---
title: Say
description: Add a message to a thread and get an agent's response
icon: message
---

The `say` function adds a user message to a thread and gets an agent's response. It transforms `str → str`, making it easy to:
- Store messages in a thread ("My name is Alice" → thread.messages += [user_msg, agent_msg])
- Get contextual responses ("What's my name?" → "Your name is Alice")
- Guide agent behavior ("You are a chef..." → "Let me suggest a recipe...")

For complex conversations, consider creating a custom task. The `say` function is a convenient wrapper around Marvin's task system - see [Tasks](/concepts/tasks) for more details.

## Usage

Add a message and get a response:

```python
import marvin

# Create a thread to store the conversation
thread = marvin.Thread()

# Get a recommendation with specific instructions
user_query = "What should I cook for dinner tonight? I'm looking for something quick and healthy."
chef_recommendation = marvin.say(
    user_query,
    instructions="Respond as a professional chef, focusing on quick and healthy options.",
    thread=thread
)
print(chef_recommendation)
# Expected output: A chef-like recommendation, e.g.,
# "For a quick and healthy dinner, I'd suggest a pan-seared salmon with asparagus and a lemon-dill sauce. It's ready in under 20 minutes!"

# Follow-up question using the same thread
follow_up_question = "That sounds good. What kind of wine would pair well with salmon?"
wine_pairing = marvin.say(
    follow_up_question,
    instructions="Respond as a sommelier.", # Note: instructions can change per 'say' call
    thread=thread
)
print(wine_pairing)
# Expected output: A sommelier-like wine pairing suggestion, e.g.,
# "A crisp Sauvignon Blanc or a light-bodied Pinot Noir would pair beautifully with salmon."
```

```text
# For a quick and healthy dinner, I'd suggest a pan-seared salmon with asparagus and a lemon-dill sauce. It's ready in under 20 minutes!
# A crisp Sauvignon Blanc or a light-bodied Pinot Noir would pair beautifully with salmon.
# (Note: Actual LLM output will vary. The lines above are examples of expected responses.)
```

## Parameters

- `message`: The message to add to the thread
- `instructions`: Optional guidance for the agent's responses
- `agent`: Optional custom agent to use
- `thread`: Optional thread to store conversation history
- `context`: Optional additional context

## Async Support

The function is also available in an async version:

```python
import marvin
import asyncio

async def main():
    thread = marvin.Thread()
    response = await marvin.say_async(
        "What's the weather like?",
        thread=thread
    )
    print(response)

asyncio.run(main())
```

## Examples

### Remembering Context in a Conversation
The `thread` object automatically keeps track of conversation history, allowing agents to reference earlier messages:
```python
import marvin # Assuming already imported

# Create a thread (or reuse one from previous examples if running sequentially)
conversation_thread = marvin.Thread()

# Add a message and get a response
response1 = marvin.say(
    "My name is Alice",
    thread=conversation_thread
)
print(response1) # "Hello Alice! Nice to meet you."

# The agent can now reference previous messages
response2 = marvin.say(
    "What's my name?",
    thread=conversation_thread
)
print(response2) # "Your name is Alice."
```

```text
# Hello Alice! Nice to meet you.
# Your name is Alice.
# (Note: Actual LLM output will vary.)
```

### Using Tools in Conversation
You can use `say` with an agent that has tools. The agent can decide to use these tools based on the conversation.
```python
import marvin # Assuming already imported
import datetime # Add this import

# Define a simple tool
def get_current_time() -> str:
    '''Returns the current time in HH:MM AM/PM format.'''
    return datetime.datetime.now().strftime("%I:%M %p")

# Create an agent with the tool
clock_agent = marvin.Agent(
    name="ClockAgent",
    instructions="You are helpful and have access to the current time.",
    tools=[get_current_time]
)

# Create a thread
tool_thread = marvin.Thread()

# Ask a question that might use the tool
time_response = marvin.say(
    "What time is it right now?",
    agent=clock_agent,
    thread=tool_thread
)
print(time_response)
# Expected output: Something like "The current time is 03:45 PM."

# Ask another question where it might not use the tool
greeting_response = marvin.say(
    "Good afternoon!",
    agent=clock_agent,
    thread=tool_thread
)
print(greeting_response)
# Expected output: Something like "Good afternoon to you too!"
```

```text
# The current time is 03:45 PM.
# Good afternoon to you too!
# (Note: Actual LLM output, especially tool usage, will vary.)
```

### Using a Custom Agent

Use a specialized agent:

```python
import marvin

thread = marvin.Thread()
tech_agent = marvin.Agent(
    name="TechSupport",
    instructions="You are a helpful tech support agent"
)

response = marvin.say(
    "My computer won't start",
    agent=tech_agent,
    thread=thread
)
print(response)
```

```python
"Let's troubleshoot this step by step. First, check if your computer is properly plugged in and the power button lights up..."
```

### With Memory

Remember previous interactions:

```python
import marvin

thread = marvin.Thread()
agent = marvin.Agent(
    memories=[
        marvin.Memory(
            key="user_preferences",
            instructions="Remember user preferences"
        )
    ]
)

# Store preference in memory
response = marvin.say(
    "I prefer vegetarian food",
    agent=agent,
    thread=thread
)
print(response)

# Agent can access both memory and thread history
response = marvin.say(
    "What should I cook?",
    agent=agent,
    thread=thread
)
print(response)
```

```python
"I'll remember your preference for vegetarian food."
"Given your vegetarian preference, I'd suggest a delicious mushroom risotto..."
```
