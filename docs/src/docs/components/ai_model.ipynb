{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Model\n",
    "\n",
    "AI Models are a high-level component, or building block, of Marvin. Like all Marvin components, they are completely standalone: you're free to use them with or without the rest of Marvin."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition abstract\">\n",
    "  <p class=\"admonition-title\">What it does</p>\n",
    "  <p>\n",
    "    A decorator that lets you extract structured data from unstructured text, documents, or instructions.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location(city='New York', state='NY')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from marvin import ai_model\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "@ai_model\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state: str = Field(..., description=\"The two-letter state abbreviation\")\n",
    "\n",
    "\n",
    "Location(\"The Big Apple\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"admonition info\">\n",
    "  <p class=\"admonition-title\">How it works</p>\n",
    "  <p>\n",
    "    AI Models use an LLM to extract, infer, or deduce data from the provided text. The data is parsed with Pydantic into the provided schema.\n",
    "  </p>\n",
    "</div>\n",
    "<div class=\"admonition tip\">\n",
    "  <p class=\"admonition-title\">When to use</p>\n",
    "  <p>\n",
    "    <ol>\n",
    "    <li> Best for extractive tasks: structuring of text or data models.\n",
    "    <li> Best for writing NLP pipelines that would otherwise be impossible to create.\n",
    "    <li> Good for model generation, though, see AI Function.\n",
    "    </ol>\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Creating an AI Model\n",
    "\n",
    "AI Models are identical to Pydantic `BaseModels`, except that they can attempt to parse natural language to populate their fields. To build an effective AI Model, be as specific as possible with your field names, field descriptions, docstring, and instructions.\n",
    "\n",
    "To build a minimal AI model, decorate any standard Pydantic model, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location(city='New York', state='New York')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@ai_model\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state: str\n",
    "\n",
    "\n",
    "Location(\"The Big Apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "A more complete model will provide instructions wherever possible, as all available information will be sent to the LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location(city='New York', state='NY')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@ai_model\n",
    "class Location(BaseModel):\n",
    "    \"\"\"A representation of a US city and state\"\"\"\n",
    "\n",
    "    city: str = Field(description=\"The city's proper name\")\n",
    "    state: str = Field(description=\"The state's two-letter abbreviation (e.g. NY)\")\n",
    "\n",
    "\n",
    "Location(\"The Big Apple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can experiment to find the optimal blend of clarity and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring an AI Model\n",
    "\n",
    "In addition to how you define the AI model itself, there are two ways to control its behavior at runtime: `instructions` and `model`.\n",
    "\n",
    "### Providing instructions\n",
    "When parsing text, AI Models can take up to three different forms of instruction:\n",
    "- the AI Model's docstring (set at the class level)\n",
    "- instructions passed to the `@ai_model` decorator (set at the class level)\n",
    "- instructions passed to the AI Model when instantiated (set at the instance / call level)\n",
    "\n",
    "The AI Model's docstring and the `@ai_model` instructions are roughly equivalent: they are both provided when the class is defined, not when it is instantiated, and are therefore applied to every instance of the class. Users can choose to put information in either location. If you only want to use one, our recommendation is to use the docstring for clarity. Alternatively, you may prefer to put the model's documentation in the docstring (as you would for a normal Pydantic model) and put parsing instructions in the `@ai_model` decorator, since those are unique to the LLM. This is entirely a matter of preference and users should opt for whichever is more clear; both the docstring and the `@ai_model` instructions are provided to the LLM in the same way.\n",
    "\n",
    "Here is an example of an AI model with a documentation docstring and parsing instructions provided to the decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Translation(original_text='Hello, world!', translated_text='Bonjour le monde!')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@ai_model(instructions=\"Translate to French\")\n",
    "class Translation(BaseModel):\n",
    "    \"\"\"A record of original text and translated text\"\"\"\n",
    "\n",
    "    original_text: str\n",
    "    translated_text: str\n",
    "\n",
    "\n",
    "Translation(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above case, we could have also put \"translate to French\" in the docstring (and perhaps renamed the object `FrenchTranslation`, since that's the only language it can represent).\n",
    "\n",
    "The third opportunity to provide instructions is when the model is actually instantiated. These instructions are **combined** with any other instructions to guide the model behavior. Here's how we could use the same `Translation` object to handle multiple languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_text='Hello, world!' translated_text='Bonjour, le monde!'\n",
      "original_text='Hello, world!' translated_text='Hallo, Welt!'\n"
     ]
    }
   ],
   "source": [
    "@ai_model\n",
    "class Translation(BaseModel):\n",
    "    \"\"\"A record of original text and translated text\"\"\"\n",
    "\n",
    "    original_text: str\n",
    "    translated_text: str\n",
    "\n",
    "\n",
    "print(Translation(\"Hello, world!\", instructions_=\"Translate to French\"))\n",
    "print(Translation(\"Hello, world!\", instructions_=\"Translate to German\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Note that the kwarg is `instructions_` with a trailing underscore; this is to avoid conflicts with models that may have a real `instructions` field. If you accidentally pass \"instructions\" to a model without an \"instructions\" field, a helpful error will identify your mistake.\n",
    "\n",
    "Putting this all together, here is a model whose behavior is informed by a docstring on the class itself, an instruction provided to the decorator, and an instruction provided to the instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ai_model(instructions=\"Always set color_2 to 'red'\")\n",
    "class Test(BaseModel):\n",
    "    \"\"\"Always set color_1 to 'orange'\"\"\"\n",
    "\n",
    "    color_1: str\n",
    "    color_2: str\n",
    "    color_3: str\n",
    "\n",
    "\n",
    "t1 = Test(\"Hello\", instructions_=\"Always set color_3 to 'blue'\")\n",
    "assert t1 == Test(color_1=\"orange\", color_2=\"red\", color_3=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the LLM\n",
    "By default, `@ai_model` uses the global LLM settings. To specify a particular LLM, pass it as an argument to the decorator or at instantiation. If you provide it to the decorator, it becomes the default for all uses of that model. If you provide it at instantiation, it is only used for that specific model. \n",
    "\n",
    "Note that the kwarg is `model_` with a trailing underscore; this is to avoid conflicts with models that may have a real `model` field. If you accidentally pass a \"model\" kwarg and there is no \"model\" field, a helpful error will identify your mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city='New York' state='New York'\n",
      "city='New York' state='New York'\n"
     ]
    }
   ],
   "source": [
    "from marvin.llms.providers import chat_llm\n",
    "\n",
    "\n",
    "@ai_model(model=chat_llm(model=\"openai/gpt-3.5-turbo\", temperature=0))\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state: str\n",
    "\n",
    "\n",
    "print(Location(\"The Big Apple\"))\n",
    "print(\n",
    "    Location(\n",
    "        \"The Big Apple\",\n",
    "        model_=chat_llm(model=\"openai/gpt-3.5-turbo\", temperature=1),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "#### âš™ï¸ Type Safe\n",
    "`ai_model` is fully type-safe. It works out of the box with Pydantic models.\n",
    "\n",
    "#### ðŸ§  Powered by deduction\n",
    "`ai_model` gives your data model access to the knowledge and deductive power \n",
    "of a Large Language Model. This means that your data model can infer answers\n",
    "to previous impossible tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ai_model\n",
    "class Location(BaseModel):\n",
    "    city: str\n",
    "    state: str\n",
    "    country: str\n",
    "    latitude: float\n",
    "    longitude: float\n",
    "\n",
    "\n",
    "Location(\"He says he's from the windy city\")\n",
    "\n",
    "# Location(\n",
    "#   city='Chicago',\n",
    "#   state='Illinois',\n",
    "#   country='United States',\n",
    "#   latitude=41.8781,\n",
    "#   longitude=-87.6298\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples \n",
    "### Resumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "from marvin import ai_model\n",
    "\n",
    "\n",
    "@ai_model\n",
    "class Resume(BaseModel):\n",
    "    first_name: str\n",
    "    last_name: str\n",
    "    phone_number: Optional[str]\n",
    "    email: str\n",
    "\n",
    "\n",
    "Resume(\"Ford Prefect â€¢ (555) 5124-5242 â€¢ ford@prefect.io\").json(indent=2)\n",
    "\n",
    "# {\n",
    "# first_name: 'Ford',\n",
    "# last_name: 'Prefect',\n",
    "# email: 'ford@prefect.io',\n",
    "# phone: '(555) 5124-5242',\n",
    "# }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Optional, List\n",
    "from pydantic import BaseModel\n",
    "from marvin import ai_model\n",
    "\n",
    "\n",
    "class Destination(pydantic.BaseModel):\n",
    "    start: datetime.date\n",
    "    end: datetime.date\n",
    "    city: Optional[str]\n",
    "    country: str\n",
    "    suggested_attractions: list[str]\n",
    "\n",
    "\n",
    "@ai_model\n",
    "class Trip(pydantic.BaseModel):\n",
    "    trip_start: datetime.date\n",
    "    trip_end: datetime.date\n",
    "    trip_preferences: list[str]\n",
    "    destinations: List[Destination]\n",
    "\n",
    "\n",
    "Trip(\"\"\"\\\n",
    "    I've got all of June off, so hoping to spend the first\\\n",
    "    half of June in London and the second half in Rabat. I love \\\n",
    "    good food and going to museums.\n",
    "\"\"\").json(indent=2)\n",
    "\n",
    "# {\n",
    "#   \"trip_start\": \"2023-06-01\",\n",
    "#   \"trip_end\": \"2023-06-30\",\n",
    "#   \"trip_preferences\": [\n",
    "#     \"good food\",\n",
    "#     \"museums\"\n",
    "#   ],\n",
    "#   \"destinations\": [\n",
    "#     {\n",
    "#       \"start\": \"2023-06-01\",\n",
    "#       \"end\": \"2023-06-15\",\n",
    "#       \"city\": \"London\",\n",
    "#       \"country\": \"United Kingdom\",\n",
    "#       \"suggested_attractions\": [\n",
    "#         \"British Museum\",\n",
    "#         \"Tower of London\",\n",
    "#         \"Borough Market\"\n",
    "#       ]\n",
    "#     },\n",
    "#     {\n",
    "#       \"start\": \"2023-06-16\",\n",
    "#       \"end\": \"2023-06-30\",\n",
    "#       \"city\": \"Rabat\",\n",
    "#       \"country\": \"Morocco\",\n",
    "#       \"suggested_attractions\": [\n",
    "#         \"Kasbah des Oudaias\",\n",
    "#         \"Hassan Tower\",\n",
    "#         \"Rabat Archaeological Museum\"\n",
    "#       ]\n",
    "#     }\n",
    "#   ]\n",
    "# }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electronic Health Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from typing import Optional, List\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Patient(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "    is_smoker: bool\n",
    "\n",
    "\n",
    "class Diagnosis(BaseModel):\n",
    "    condition: str\n",
    "    diagnosis_date: date\n",
    "    stage: Optional[str] = None\n",
    "    type: Optional[str] = None\n",
    "    histology: Optional[str] = None\n",
    "    complications: Optional[str] = None\n",
    "\n",
    "\n",
    "class Treatment(BaseModel):\n",
    "    name: str\n",
    "    start_date: date\n",
    "    end_date: Optional[date] = None\n",
    "\n",
    "\n",
    "class Medication(Treatment):\n",
    "    dose: Optional[str] = None\n",
    "\n",
    "\n",
    "class BloodTest(BaseModel):\n",
    "    name: str\n",
    "    result: str\n",
    "    test_date: date\n",
    "\n",
    "\n",
    "@ai_model\n",
    "class PatientData(BaseModel):\n",
    "    patient: Patient\n",
    "    diagnoses: List[Diagnosis]\n",
    "    treatments: List[Treatment]\n",
    "    blood_tests: List[BloodTest]\n",
    "\n",
    "\n",
    "PatientData(\"\"\"\\\n",
    "Ms. Lee, a 45-year-old patient, was diagnosed with type 2 diabetes mellitus on 06-01-2018.\n",
    "Unfortunately, Ms. Lee's diabetes has progressed and she developed diabetic retinopathy on 09-01-2019.\n",
    "Ms. Lee was diagnosed with type 2 diabetes mellitus on 06-01-2018.\n",
    "Ms. Lee was initially diagnosed with stage I hypertension on 06-01-2018.\n",
    "Ms. Lee's blood work revealed hyperlipidemia with elevated LDL levels on 06-01-2018.\n",
    "Ms. Lee was prescribed metformin 1000 mg daily for her diabetes on 06-01-2018.\n",
    "Ms. Lee's most recent A1C level was 8.5% on 06-15-2020.\n",
    "Ms. Lee was diagnosed with type 2 diabetes mellitus, with microvascular complications, including diabetic retinopathy, on 09-01-2019.\n",
    "Ms. Lee's blood pressure remains elevated and she was prescribed lisinopril 10 mg daily on 09-01-2019.\n",
    "Ms. Lee's most recent lipid panel showed elevated LDL levels, and she was prescribed atorvastatin 40 mg daily on 09-01-2019.\\\n",
    "\"\"\").json(indent=2)\n",
    "\n",
    "# {\n",
    "#   \"patient\": {\n",
    "#     \"name\": \"Ms. Lee\",\n",
    "#     \"age\": 45,\n",
    "#     \"is_smoker\": false\n",
    "#   },\n",
    "#   \"diagnoses\": [\n",
    "#     {\n",
    "#       \"condition\": \"Type 2 diabetes mellitus\",\n",
    "#       \"diagnosis_date\": \"2018-06-01\",\n",
    "#       \"stage\": \"I\",\n",
    "#       \"type\": null,\n",
    "#       \"histology\": null,\n",
    "#       \"complications\": null\n",
    "#     },\n",
    "#     {\n",
    "#       \"condition\": \"Diabetic retinopathy\",\n",
    "#       \"diagnosis_date\": \"2019-09-01\",\n",
    "#       \"stage\": null,\n",
    "#       \"type\": null,\n",
    "#       \"histology\": null,\n",
    "#       \"complications\": null\n",
    "#     }\n",
    "#   ],\n",
    "#   \"treatments\": [\n",
    "#     {\n",
    "#       \"name\": \"Metformin\",\n",
    "#       \"start_date\": \"2018-06-01\",\n",
    "#       \"end_date\": null\n",
    "#     },\n",
    "#     {\n",
    "#       \"name\": \"Lisinopril\",\n",
    "#       \"start_date\": \"2019-09-01\",\n",
    "#       \"end_date\": null\n",
    "#     },\n",
    "#     {\n",
    "#       \"name\": \"Atorvastatin\",\n",
    "#       \"start_date\": \"2019-09-01\",\n",
    "#       \"end_date\": null\n",
    "#     }\n",
    "#   ],\n",
    "#   \"blood_tests\": [\n",
    "#     {\n",
    "#       \"name\": \"A1C\",\n",
    "#       \"result\": \"8.5%\",\n",
    "#       \"test_date\": \"2020-06-15\"\n",
    "#     },\n",
    "#     {\n",
    "#       \"name\": \"LDL\",\n",
    "#       \"result\": \"Elevated\",\n",
    "#       \"test_date\": \"2018-06-01\"\n",
    "#     },\n",
    "#     {\n",
    "#       \"name\": \"LDL\",\n",
    "#       \"result\": \"Elevated\",\n",
    "#       \"test_date\": \"2019-09-01\"\n",
    "#     }\n",
    "#   ]\n",
    "# }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "from django.db.models import Q\n",
    "\n",
    "\n",
    "class DjangoLookup(BaseModel):\n",
    "    field: Literal[*django_fields]\n",
    "    lookup: Literal[*django_lookups] = pydantic.Field(description=\"e.g. __iregex\")\n",
    "    value: Any\n",
    "\n",
    "\n",
    "@ai_model\n",
    "class DjangoQuery(BaseModel):\n",
    "    \"\"\"A model representing a Django ORM query\"\"\"\n",
    "\n",
    "    lookups: List[DjangoLookup]\n",
    "\n",
    "    def to_q(self) -> Q:\n",
    "        q = Q()\n",
    "        for lookup in self.lookups:\n",
    "            q &= Q(**{f\"{lookup.field}__{lookup.lookup}\": lookup.value})\n",
    "        return q\n",
    "\n",
    "\n",
    "DjangoQuery(\"\"\"\\\n",
    "    All users who joined more than two months ago but\\\n",
    "    haven't made a purchase in the last 30 days\"\"\").to_q()\n",
    "\n",
    "# <Q: (AND:\n",
    "#     ('date_joined__lte', '2023-03-11'),\n",
    "#     ('last_purchase_date__isnull', False),\n",
    "#     ('last_purchase_date__lte', '2023-04-11'))>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Financial Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "@ai_model\n",
    "class CapTable(BaseModel):\n",
    "    total_authorized_shares: int\n",
    "    total_common_share: int\n",
    "    total_common_shares_outstanding: Optional[int]\n",
    "    total_preferred_shares: int\n",
    "    conversion_price_multiple: int = 1\n",
    "\n",
    "\n",
    "CapTable(\"\"\"\\\n",
    "    In the cap table for Charter, the total authorized shares amount to 13,250,000. \n",
    "    The total number of common shares stands at 10,000,000 as specified in Article Fourth, \n",
    "    clause (i) and Section 2.2(a)(i). The exact count of common shares outstanding is not \n",
    "    available at the moment. Furthermore, there are a total of 3,250,000 preferred shares mentioned \n",
    "    in Article Fourth, clause (ii) and Section 2.2(a)(ii). The dividend percentage for Charter is \n",
    "    set at 8.00%. Additionally, the mandatory conversion price multiple is 3x, which is \n",
    "    derived from the Term Sheet.\\\n",
    "\"\"\").json(indent=2)\n",
    "\n",
    "# {\n",
    "#   \"total_authorized_shares\": 13250000,\n",
    "#   \"total_common_share\": 10000000,\n",
    "#   \"total_common_shares_outstanding\": null,\n",
    "#   \"total_preferred_shares\": 3250000,\n",
    "#   \"conversion_price_multiple\": 3\n",
    "# }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meeting Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import Literal\n",
    "from marvin import ai_model\n",
    "\n",
    "\n",
    "class ActionItem(BaseModel):\n",
    "    responsible: str\n",
    "    description: str\n",
    "    deadline: Optional[datetime.datetime]\n",
    "    time_sensitivity: Literal[\"low\", \"medium\", \"high\"]\n",
    "\n",
    "\n",
    "@ai_model\n",
    "class Conversation(BaseModel):\n",
    "    \"\"\"A class representing a team conversation\"\"\"\n",
    "\n",
    "    participants: List[str]\n",
    "    action_items: List[ActionItem]\n",
    "\n",
    "\n",
    "Conversation(\"\"\"\n",
    "    Adam: Hey Jeremiah can you approve my PR? I requested you to review it.\n",
    "    Jeremiah: Yeah sure, when do you need it done by?\n",
    "    Adam: By this Friday at the latest, we need to ship it by end of week.\n",
    "    Jeremiah: Oh shoot, I need to make sure that Nate and I have a chance to chat first.\n",
    "    Nate: Jeremiah we can meet today to chat.\n",
    "    Jeremiah: Okay, I'll book something for today.\n",
    "\"\"\").json(indent=2)\n",
    "\n",
    "# {\n",
    "#   \"participants\": [\n",
    "#     \"Adam\",\n",
    "#     \"Jeremiah\",\n",
    "#     \"Nate\"\n",
    "#   ],\n",
    "#   \"action_items\": [\n",
    "#     {\n",
    "#       \"responsible\": \"Jeremiah\",\n",
    "#       \"description\": \"Approve Adam's PR\",\n",
    "#       \"deadline\": \"2023-05-12T23:59:59\",\n",
    "#       \"time_sensitivity\": \"high\"\n",
    "#     },\n",
    "#     {\n",
    "#       \"responsible\": \"Jeremiah\",\n",
    "#       \"description\": \"Book a meeting with Nate\",\n",
    "#       \"deadline\": \"2023-05-11T23:59:59\",\n",
    "#       \"time_sensitivity\": \"high\"\n",
    "#     }\n",
    "#   ]\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marvin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
