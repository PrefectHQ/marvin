{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI\n",
    "\n",
    "Marvin includes first-class utilities for working with OpenAI's API. It's familiar, cuts boiler-plate, and - most importantly - optional. It's the type of stuff you'd build after your first or second refactor. Fingers crossed it saves you as much dev time as it's saved us. \n",
    "\n",
    "If you're looking for something higher-level, check out the rest of the docs. This section is for folks who prefer to work with a lower-level API but still appreciate a little syntactic sugar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatCompletion\n",
    "\n",
    "Marvin includes a subclass of OpenAI's SDK implementation of ChatCompletion. This utility is completely standalone: you're free to use it with or without Marvin's other components or framework.\n",
    "\n",
    "### Frozen Keyword Arguments\n",
    "\n",
    "In `openai.ChatCompletion`, you normally have to pass keyword arguments to each invocation of `create` and `acreate`. With *Marvin*, you can choose to pass these keywords to the constructor of `marvin.openai.ChatCompletion`, and have those keywords passed to each subsequent invocation. This let's you do stuff like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marvin\n",
    "\n",
    "marvin.openai.ChatCompletion(model=\"gpt-3.5-turbo\").create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke!\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This small quality-of-life change let's you do some pretty great things, like:\n",
    "\n",
    "#### Creating Model Facets\n",
    "\n",
    "By freezing keyword arguments this lets us define, premission, and version `facets` of ChatGPT. This let's us define separate model instances for internal, public, or customer use. By combining this with function calling (see below), we can also give smart models access to smarter models when they intuit that it's prudent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marvin\n",
    "\n",
    "# Define a smart model.\n",
    "gpt3 = marvin.openai.ChatCompletion(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Define a smarter model.\n",
    "gpt4 = marvin.openai.ChatCompletion(model=\"gpt-4\")\n",
    "\n",
    "# gp4.create(**kwargs) ~ openai.ChatCompletion.create(model = 'gpt-4', **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, each instance passes its respective `model` keyword argument to create and acreate on each invocation. \n",
    "\n",
    "#### Facet Inheritence\n",
    "\n",
    "Of course, these model configurations are chainable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import marvin\n",
    "\n",
    "pirate_system_message = {\"role\": \"system\", \"content\": \"You talk like a pirate\"}\n",
    "\n",
    "# Define a smart, public model.\n",
    "smart_pirate = gpt3(messages=[pirate_system_message]).create(\n",
    "    [{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, keyword arguments in create and acreate override frozen parameters. This default has two exceptions: messages and functions, wherein passed messages are concatenated with frozen messages (and likewise for functions)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "OpenAI's ChatCompletion API enables you to pass a list of `functions` for it to optionally call in service of a query. If it chooses to execute a function, either by choice or instruction, it will return the function's name along with its formatted parameters for *you* to evaluate. The OpenAI schema accepts a JSON Schema representation of your functions.\n",
    "\n",
    "Marvin includes lightweight utilities for working with OpenAI's function API. These utilities are completely standalone: you're free to use them with or without Marvin's other components or framework. We expose `openai_fn`, a function decorator that makes working with OpenAI functions straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.openai import openai_fn\n",
    "\n",
    "\n",
    "@openai_fn\n",
    "def add(x: int, y: int) -> str:\n",
    "    return x + y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization\n",
    "\n",
    "*Marvin* allows auto creation of JSON Schemas from functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.openai import openai_fn\n",
    "\n",
    "\n",
    "@openai_fn\n",
    "def add(x: int, y: int) -> str:\n",
    "    \"\"\"Adds two numbers together\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "add.schema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Returns its JSON Schema to use with OpenAI's function API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"name\": \"add\",\n",
    "    \"description\": \"Adds two numbers together\",\n",
    "    \"parameters\": {\n",
    "        \"x\": {\"type\": \"int\", \"description\": null},\n",
    "        \"y\": {\"type\": \"int\", \"description\": null},\n",
    "        \"required\": [\"x\", \"y\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "When ChatGPT decides it needs to invoke a function in service of your query, it will return the name of the function it would like you to invoke and the arguments to evaluate it with. *Marvin* provides means to evaluate a function from a ChatGPT Function Call Response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from marvin.openai import openai_fn\n",
    "\n",
    "\n",
    "@openai_fn\n",
    "def add(x: int, y: int) -> str:\n",
    "    \"\"\"Adds two numbers together\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is 123123 + 85858?\"}]\n",
    ")\n",
    "\n",
    "add.from_response(response) == 208981"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registry\n",
    "\n",
    "In most function-calling applications, you'll want to pass a list of several functions. The developer experience, accordingly, gets `n` times worse. We introduce a standard Function Registry to make things a little easier. It doubles as an API Router if you're into that sort of thing.\n",
    "\n",
    "#### Serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.openai import OpenAIFunctionRegistry\n",
    "\n",
    "registry = OpenAIFunctionRegistry()\n",
    "\n",
    "\n",
    "@registry.register\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two numbers together\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "@registry.register\n",
    "def subtract(x: int, y: int) -> int:\n",
    "    \"\"\"Subtracts `y` from `x`\"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "registry.schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which yields a list of schemas which can be passed as a keyword argument to OpenAI's SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    {\n",
    "        \"name\": \"add\",\n",
    "        \"description\": \"Adds two numbers together\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"x\": {\"title\": \"X\", \"type\": \"integer\"},\n",
    "                \"y\": {\"title\": \"Y\", \"type\": \"integer\"},\n",
    "            },\n",
    "            \"required\": [\"x\", \"y\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"subtract\",\n",
    "        \"description\": \"Subtracts `y` from `x`\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"x\": {\"title\": \"X\", \"type\": \"integer\"},\n",
    "                \"y\": {\"title\": \"Y\", \"type\": \"integer\"},\n",
    "            },\n",
    "            \"required\": [\"x\", \"y\"],\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "When ChatGPT decides it needs to invoke one of the functions in your registry in service of your query, it will return the name of the function it would like you to invoke and the arguments to evaluate it with. *Marvin* provides means to evaluate a function call in your registry dictated by a ChatGPT Function Call Response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.openai import OpenAIFunctionRegistry\n",
    "\n",
    "registry = OpenAIFunctionRegistry()\n",
    "\n",
    "\n",
    "@registry.register\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two numbers together\"\"\"\n",
    "    return x + y\n",
    "\n",
    "\n",
    "@registry.register\n",
    "def subtract(x: int, y: int) -> int:\n",
    "    \"\"\"Subtracts `y` from `x`\"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is 123123 - 85858?\"}]\n",
    ")\n",
    "\n",
    "registry.from_response(response) == 37265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Composability\n",
    "\n",
    "Given two function routers, you can easily compose them. This lets you separately define, say, one registry devoted to accessing and processing one data source, and another devoted to accessing and processing another (with stricter permissions, perhaps). Including them is as straightfoward as calling `include` (which is, of course, idempotent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math = OpenAIFunctionRegistry()\n",
    "\n",
    "arithmetic = OpenAIFunctionRegistry()\n",
    "\n",
    "trigonometry = OpenAIFunctionRegistry()\n",
    "\n",
    "\n",
    "@arithmetic.register\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"\"\"Adds two numbers together\"\"\"\n",
    "\n",
    "\n",
    "@trigonometry.register\n",
    "def tan(theta: float) -> float:\n",
    "    \"\"\"Calculates the tangent of `theta`.\"\"\"\n",
    "    return x - y\n",
    "\n",
    "\n",
    "math.include(arithmetic)\n",
    "math.include(trigonometry)\n",
    "\n",
    "math.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"functions\": [\n",
    "        {\n",
    "            \"name\": \"add\",\n",
    "            \"description\": \"Adds two numbers together\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"x\": {\"title\": \"X\", \"type\": \"integer\"},\n",
    "                    \"y\": {\"title\": \"Y\", \"type\": \"integer\"},\n",
    "                },\n",
    "                \"required\": [\"x\", \"y\"],\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"tan\",\n",
    "            \"description\": \"Calculates the tangent of `theta`.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"theta\": {\"title\": \"Theta\", \"type\": \"number\"}},\n",
    "                \"required\": [\"theta\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"function_call\": \"auto\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Generation\n",
    "\n",
    "*Marvin* offers an experimental utility to author code using OpenAI's function API. Given a function with a typed signature and a docstring, we can write entire functions in the language of your choice. Simple call `.code()` on a function decorated with @openai_fn. \n",
    "\n",
    "Behind the scenes, we define a utility function write_code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.openai import openai_fn\n",
    "\n",
    "\n",
    "@openai_fn\n",
    "def write_code(\n",
    "    language: str,\n",
    "    filename: str,\n",
    "    name: str,\n",
    "    docstring: str,\n",
    "    code: str,\n",
    ") -> str:\n",
    "    \"\"\"Accepts and checks expertly staff engineer quality written `code` in `language`\"\"\"\n",
    "    return (language, filename, name, docstring, code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you call the `code` method on *your* openai_fn, we simply call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@openai_fn\n",
    "def add(x: int, y: int) -> str:\n",
    "    \"\"\"Adds two numbers together\"\"\"\n",
    "    # There is no code here! #\n",
    "\n",
    "\n",
    "{\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"A function in python that described by the following schema:\\n {add.schema}\"\"\",\n",
    "        },\n",
    "    ],\n",
    "    **write_code.schema,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns the following payload for you to send to OpenAI, which forces it to write code that satisfies the high-level description of your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    'messages': \n",
    "    [{\n",
    "        'role': 'user',\n",
    "        'content': \"A function in python that described by the following schema:\n",
    "            {'name': 'add', \n",
    "             'description': 'Adds two numbers together', \n",
    "             'parameters': {\n",
    "                 'type': 'object', \n",
    "                 'properties': {\n",
    "                     'x': {'title': 'X', 'type': 'integer'}, \n",
    "                     'y': {'title': 'Y', 'type': 'integer'}\n",
    "                }, 'required': ['x', 'y']\n",
    "            }\n",
    "        }\"\n",
    "    }],\n",
    "    'functions': [\n",
    "        {\n",
    "            'name': 'write_code',\n",
    "            'description': 'Accepts and checks expertly staff engineer quality written `code` in `language`',\n",
    "            'parameters': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'language': {'title': 'Language', 'type': 'string'},\n",
    "                    'filename': {'title': 'Filename', 'type': 'string'},\n",
    "                    'name': {'title': 'Name', 'type': 'string'},\n",
    "                    'docstring': {'title': 'Docstring', 'type': 'string'},\n",
    "                    'code': {'title': 'Code', 'type': 'string'}},\n",
    "            'required': ['language', 'filename', 'name', 'docstring', 'code']\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    'function_call': {'name': 'write_code'}\n",
    "}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we give it a trivial example and call `.code()`, we see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marvin.openai import openai_fn\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"YOUR_OPENAPI_KEY\"\n",
    "\n",
    "\n",
    "@openai_fn\n",
    "def add(x: int, y: int) -> str:\n",
    "    \"\"\"Adds two numbers together\"\"\"\n",
    "    # There is no code here! #\n",
    "\n",
    "\n",
    "write_code_instructions = add.code()\n",
    "\n",
    "response = await openai.ChatCompletion.acreate(\n",
    "    model=\"gpt-3.5-turbo\", **write_code_instructions\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.get(\"function_call\").get(\"arguments\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"language\": \"python\",\n",
    "    \"filename\": \"add.py\",\n",
    "    \"name\": \"add\",\n",
    "    \"docstring\": \"Adds two numbers together\",\n",
    "    \"code\": \"def add(x: int, y: int) -> int:\\n    return x + y\",\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
